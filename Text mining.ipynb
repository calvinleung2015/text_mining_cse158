{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wingfungleung/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/wingfungleung/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "dataset = list(parse('train_Category.json.gz'))[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling data\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many unique bigrams are there amongst the reviews? List the 5 most-frequently-occurring bigrams along with their number of occurrences in the corpus (1 mark).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique words in the train set\n",
    "biwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    nltk_tokens = nltk.word_tokenize(r)\n",
    "    bigrams = list(nltk.bigrams(nltk_tokens))\n",
    "    for i in bigrams:\n",
    "        biwordCount[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4441, ('this', 'game')),\n",
       " (4263, ('the', 'game')),\n",
       " (3359, ('of', 'the')),\n",
       " (2041, ('if', 'you')),\n",
       " (2017, ('in', 'the'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bicounts = [(biwordCount[w], w) for w in biwordCount]\n",
    "bicounts.sort()\n",
    "bicounts.reverse()\n",
    "common_five_words = [(x[0], x[1]) for x in bicounts[:5]]\n",
    "common_five_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique bigrams:  256326\n"
     ]
    }
   ],
   "source": [
    "print('number of unique bigrams: ', len(biwordCount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The code provided performs least squares using the 1000 most common unigrams. Adapt it to use the 1000 most common bigrams and report the MSE obtained using the new predictor (use bigrams only, i.e., not unigrams+bigrams) (1 mark). Note that the code performs regularized regression with a regularization parameter of 1.0. The prediction target should be log2(hours + 1) (i.e., our transformed time variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_1000_biwords = [(x[0], x[1]) for x in bicounts[:1000]]\n",
    "biwords = [x[1] for x in bicounts[:1000]]\n",
    "wordId = dict(zip(biwords, range(len(biwords))))\n",
    "wordSet = set(biwords)\n",
    "\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(biwords)\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    nltk_tokens = nltk.word_tokenize(r)\n",
    "    bigrams = list(nltk.bigrams(nltk_tokens))\n",
    "    for i in bigrams:\n",
    "        if i in biwords:\n",
    "            feat[wordId[i]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in dataset]\n",
    "\n",
    "y = [d['hours'] for d in dataset]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "# # Regression\n",
    "# theta,residuals,rank,s = np.linalg.lstsq(X, y, rcond=None)\n",
    "# theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error:  4.391761206363515\n"
     ]
    }
   ],
   "source": [
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Repeat the above experiment using unigrams and bigrams, still considering the 1000 most common. That is, your model will still use 1000 features (plus an offset), but those 1000 features will be some combination of unigrams and bigrams. Report the MSE obtained using the new predictor (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram\n",
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        uniwordCount[w] += 1\n",
    "    \n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "common_1000_uniwords = [(x[0], x[1]) for x in unicounts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine bigrams and unigrams words\n",
    "unibi_lst = common_1000_biwords + common_1000_uniwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "random.shuffle(unibi_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 features with some combination of unigrams and bigrams.\n",
    "unibiCount = unibi_lst[:1000]\n",
    "\n",
    "common_1000_unibiwords = [(x[0], x[1]) for x in unibiCount[:1000]]\n",
    "unibiwords = [x[1] for x in unibiCount[:1000]]\n",
    "wordId = dict(zip(unibiwords, range(len(unibiwords))))\n",
    "wordSet = set(unibiwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature2(datum):\n",
    "    feat = [0]*len(unibiwords)\n",
    "    #bigrams\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    nltk_tokens = nltk.word_tokenize(r)\n",
    "    bigrams = list(nltk.bigrams(nltk_tokens))\n",
    "    for i in bigrams:\n",
    "        if i in unibiwords:\n",
    "            feat[wordId[i]] += 1\n",
    "    #unigrams\n",
    "    r = ''.join([c for c in datum['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in unibiwords:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error:  4.284546029778992\n"
     ]
    }
   ],
   "source": [
    "X = [feature2(d) for d in dataset]\n",
    "\n",
    "y = [d['hours'] for d in dataset]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the inverse document frequency of the words ‘destiny’, ‘annoying’, ‘likeable’, ‘chapter’, and ‘interesting’? What are their tf-idf scores in review ID r75487422 (using log base 10, unigrams only, following the first definition of tf-idf given in the slides) (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [ 'destiny', 'annoying', 'likeable', 'chapter', 'interesting']\n",
    "wordDict = dict.fromkeys(words, 0)\n",
    "word_list = []\n",
    "for d in dataset:\n",
    "    wordDict = dict.fromkeys(words, 0)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destiny': 7.824046010856292,\n",
       " 'annoying': 4.2336066295556085,\n",
       " 'likeable': 7.1308988302963465,\n",
       " 'chapter': 5.115995809754082,\n",
       " 'interesting': 3.128121461599737}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(dataset)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short Review:\n",
      "A good starting chapter for this series, despite the main character being annoying (for now) and a short length. The story is good and actually gets more interesting. Worth the try.\n",
      "Long Review:\n",
      "Blackwell Legacy is the first on the series of (supposedly) 5 games that talks about the main protagonist, Rosangela Blackwell, as being a so called Medium, and in this first chapter we get to know how her story will start and how she will meet her adventure companion Joey...and really, that's really all for for now and that's not a bad thing, because in a way this game wants to show how hard her new job is, and that she cannot escape her destiny as a medium.\n",
      "My biggest complain for this chapter, except the short length, it's the main protagonist being a \"bit\" too annoying to be likeable, and most of her dialogues will always be about complaining or just be annoyed. Understandable, sure, but lighten' up will ya!?\n",
      "However, considering that in the next installments she will be much more likeable and kind of interesting, I'd say give it a shot and see if you like it: if you hate this first game, you might like the next, or can always stop here.\n",
      "I recommend it.\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for d in dataset:\n",
    "    if d['reviewID'] == 'r75487422':\n",
    "        print(d['text'])\n",
    "        break  \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destiny': 7.824046010856292,\n",
       " 'annoying': 8.467213259111217,\n",
       " 'likeable': 14.261797660592693,\n",
       " 'chapter': 15.347987429262247,\n",
       " 'interesting': 6.256242923199474}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_list[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Adapt your unigram model to use the tfidf scores of words, rather than a bag-of-words representation. That is, rather than your features containing the word counts for the 1000 most common unigrams, it should contain tfidf scores for the 1000 most common unigrams. Report the MSE of this new model (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigram\n",
    "uniwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in dataset:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        uniwordCount[w] += 1\n",
    "    \n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "common_1000_uniwords = [(x[0], x[1]) for x in unicounts[:1000]]\n",
    "uniwords = [ d[1] for d in common_1000_uniwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for d in dataset:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(dataset)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def feature3(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature3(i, dataset[i]) for i in range(len(dataset))]\n",
    "y = [d['hours'] for d in dataset]\n",
    "y = [math.log2(d+1) for d in y] #transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square error:  5.195723126763592\n"
     ]
    }
   ],
   "source": [
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which other review has the highest cosine similarity compared to review ID r75487422, in terms of their tf-idf representations (considering unigrams only). Provide the reviewID, or the text of the review (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for d in dataset:\n",
    "    if d['reviewID'] == 'r75487422':\n",
    "        break  \n",
    "    index += 1\n",
    "\n",
    "score = []\n",
    "for i in range(len(dataset)):\n",
    "    if i != index:\n",
    "        score.append((cosine_similarity([X[i]], [X[index]])[0][0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9833646596609258, 7919)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score = max(score)\n",
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tried to play this game in a Petco the other day and got escorted out by security. They thought I only put one ferret down my pants though, so I got out of there with four of those ♥♥♥♥ers for free! Man ferrets are ♥♥♥♥ing crazy and after what I experienced I can only assume that these creatures see human taint as their biggest natural predator. They ripped me up real good and turned me into a human sock puppet.\\nHey did you know ferrets arew the only species in the animal kingdom that feel regret? In the case of this game, I\\'m pretty sure all of those little ♥♥♥♥s regret being born in ♥♥♥♥ing Scotland, the only country where this♥♥♥♥♥♥won\\'t get you a court date. Then again in America we have a sport we like to call \"is this cop gonna shoot me?\" but much like basketball it\\'s not for white people, so hey I guess every country has its quirks!\\nAnyway thanks Petco for this new fur coat I just made, gonna wear it to my next crisis actor meet n greet at bohemian grove. There\\'s no ferrets in those wood so I\\'ll just stuff a a wolf down my pants and see how long it takes to eat its way through my body. LOL hail satan'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[max_score[1]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Implement a validation pipeline for this same data, by randomly shuffling the data, using 10,000 reviews for training, another 100,000 for validation, and another 10,000 for testing. Consider regularization parameters in the range{0.01, 0.1, 1, 10, 100}, and report MSEs on the test set for the model that performs best on the validation set. Using this pipeline, compare the following alternatives in terms of their performance(all using 1,000 dimensional word features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "dataset = list(parse('train_Category.json.gz'))\n",
    "#shuffling data\n",
    "random.shuffle(dataset)\n",
    "train_set = dataset[:10000]\n",
    "validation_set = dataset[10000:20000]\n",
    "test_set = dataset[20000:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigrams, keep punctuation, with tfidf scores\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in train_set:\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf\n",
    "word_list = []\n",
    "for d in train_set:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)\n",
    "    \n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "\n",
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(train_set)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model1(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, train_set[i]) for i in range(len(train_set))]\n",
    "y = [d['hours'] for d in train_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse for validation set\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in validation_set:\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n",
    "\n",
    "word_list = []\n",
    "for d in validation_set:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)\n",
    "    \n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "\n",
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(validation_set)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))\n",
    "    \n",
    "\n",
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model1(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, validation_set[i]) for i in range(len(validation_set))]\n",
    "y = [d['hours'] for d in validation_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unigrams, discard punctuation, with tfidf scores\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in train_set:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n",
    "\n",
    "\n",
    "\n",
    "#tfidf\n",
    "word_list = []\n",
    "for d in train_set:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)\n",
    "    \n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "\n",
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(train_set)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))\n",
    "    \n",
    "    \n",
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model1(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, train_set[i]) for i in range(len(train_set))]\n",
    "y = [d['hours'] for d in train_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "\n",
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "\n",
    "\n",
    "#mse for validation set\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in validation_set:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n",
    "\n",
    "word_list = []\n",
    "for d in validation_set:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)\n",
    "    \n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "\n",
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(validation_set)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))\n",
    "    \n",
    "\n",
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model1(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, validation_set[i]) for i in range(len(validation_set))]\n",
    "y = [d['hours'] for d in validation_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unigrams, without punctuation, with counts\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in train_set:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n",
    "\n",
    "\n",
    "\n",
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model2(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, train_set[i]) for i in range(len(train_set))]\n",
    "y = [d['hours'] for d in train_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "\n",
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "\n",
    "\n",
    "#mse for validation set\n",
    "uniwordCount = defaultdict(int)\n",
    "for d in validation_set:\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        uniwordCount[w] += 1\n",
    "    \n",
    "\n",
    "unicounts = [(uniwordCount[w], w) for w in uniwordCount]\n",
    "unicounts.sort()\n",
    "unicounts.reverse()\n",
    "uniwords = [ d[1] for d in unicounts]\n",
    "\n",
    "word_list = []\n",
    "for d in validation_set:\n",
    "    wordDict = dict.fromkeys(uniwords, 0)\n",
    "    r = ''.join([c for c in d['text'].lower()])\n",
    "    tokens = word_tokenize(r)\n",
    "    for w in tokens:\n",
    "        if w in uniwords:\n",
    "            wordDict[w] += 1\n",
    "    word_list.append(wordDict)\n",
    "    \n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "idf = computeIDF(word_list)\n",
    "\n",
    "tfidf_list = []\n",
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "for i in range(len(validation_set)):\n",
    "    tfidf_list.append(computeTFIDF(word_list[i],idf))\n",
    "    \n",
    "\n",
    "wordId = dict(zip(uniwords, range(len(uniwords))))\n",
    "wordSet = set(uniwords)\n",
    "def model2(index, datum):\n",
    "    feat = [0]*len(uniwords)\n",
    "    r = ''.join([c for c in d['text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in uniwords:\n",
    "            feat[wordId[w]] = tfidf_list[index][w]\n",
    "    feat.append(1) #offset\n",
    "    return feat\n",
    "\n",
    "X = [model1(i, validation_set[i]) for i in range(len(validation_set))]\n",
    "y = [d['hours'] for d in validation_set]\n",
    "y = [math.log2(d+1) for d in y] #transformed\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "print('mean square error: ', mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
